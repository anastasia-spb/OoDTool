# Embedders + Classifiers

For dataset analysis it's necessary to represent every image with feature vectors.
You can select any method (e.g. lower-level features, such as BRIEF or high-level features obtained by neural networks).
Or you can use one of embedders supported by OoDTool.

## Required format for output

Output file extension shall be ".emd.pkl"


| relative_path                               |          labels          | test_sample |   label |       embedding |                  class_probabilities |
|---------------------------------------------|:------------------------:|------------:|--------:|----------------:|-------------------------------------:|
| BalloonsBubbles/bubble/test/bubble_2.jpg    |     bubble, balloon      |        True |  bubble |   1D np.ndarray | np.ndarray of shape(len(labels) + 1) |
| BalloonsBubbles/balloon/train/balloons3.jpg |     bubble, balloon      |       False | balloon |   1D np.ndarray | np.ndarray of shape(len(labels) + 1) |


<span style="color:#59afe1"> Why do we need class_probabilities column? </span>

In case your dataset doesn't have ground truth, it's possible to use predicted probability for training.
If you plan to use GT for classification, just fill this column with zeros.

<span style="color:#59afe1"> Why length of class probabilities generated by embedder is greater than number of labels in provided dataset? </span>

If model selected for inference was pretrained on more classes than dataset contains, we assume that other categories are not in
our interest, but still would like to store, if sample was misclassified. Therefore, we store max probability at last place in probabilities array
when sample is misclassified. 
If model and database operate with same classes, at last place of probabilities array will be always zero.

## OoDTool Embedders

OoDTool implements wrappers for <a href="https://github.com/pytorch/vision/blob/main/torchvision/models/alexnet.py"> AlexNet </a>,
<a href="https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/resnet.py"> ResNet </a> and 
<a href="https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/densenet.py"> Densenet </a> models.

ResNet and Densenet models are created with <a href="https://timm.fast.ai/"> `timm` </a> deep-learning library implemented by <a href="https://github.com/rwightman"> Ross Wightman </a>.

There are several inference scenarios:
1. Generate only embeddings using one of supported pretrained timm models.
In case your dataset contains only labels from <a href="https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a"> ImageNet </a>  
dataset, then 

For these models you can either use your own pretrained weights and labels or generate embeddings with pretrained on ImageNet weights.

You can add wrapper for any model as soon as it will provide predictions and embeddings.
There are also scrips for training models on selected data.

## Usage 

```bash
$ python3 run.py -meta "DogsCats.meta.pkl" -d "example_data/DogsCats" --grads
``` 

``grads`` option will force a model to store gradients when backpropagating and store saliency map for every image.
It might increase memory consumption and slow down inference. 

